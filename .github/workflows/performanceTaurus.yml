name: Performance Tests (Taurus with JMeter)

on:
  workflow_dispatch:
    inputs:
      test_scenario:
        description: 'Test scenario to run'
        required: false
        default: 'load-test.yml'
      duration:
        description: 'Test duration (minutes)'
        required: false
        default: '5'

jobs:
  performance:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      # 1Ô∏è‚É£ Checkout del c√≥digo
      - name: Checkout code
        uses: actions/checkout@v4

      # 2Ô∏è‚É£ Configurar Java 17
      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: '17'

      # 3Ô∏è‚É£ Instalar JMeter
      - name: Install JMeter
        run: |
          JMETER_VERSION="5.6.3"
          
          echo "Installing JMeter ${JMETER_VERSION}..."
          curl -L "https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-${JMETER_VERSION}.tgz" \
            | tar -xz
          
          sudo mv "apache-jmeter-${JMETER_VERSION}" /opt/jmeter
          
          # Agregar JMeter al PATH
          echo "/opt/jmeter/bin" >> $GITHUB_PATH
          
          # Verificar instalaci√≥n
          /opt/jmeter/bin/jmeter --version

      # 4Ô∏è‚É£ Install JMeter Plugins (CORRECT APPROACH)
      - name: Instalar Plugins de JMeter (Soluci√≥n Completa)
        run: |
          # 1. Descargar Plugin Manager en la ubicaci√≥n CORRECTA
          curl -L https://jmeter-plugins.org/get/ \
            -o /opt/jmeter/lib/ext/jmeter-plugins-manager.jar
          
          # 2. Descargar CmdRunner en la ubicaci√≥n CORRECTA
          curl -L https://repo1.maven.org/maven2/kg/apc/cmdrunner/2.3/cmdrunner-2.3.jar \
            -o /opt/jmeter/lib/cmdrunner-2.3.jar
          
          # 3. EJECUTAR JMETER POR PRIMERA VEZ (ESTO ES CR√çTICO)
          /opt/jmeter/bin/jmeter --version 2>&1 | head -5
          
          # 4. Instalar los plugins que necesitas
          cd /opt/jmeter
          java -cp lib/ext/jmeter-plugins-manager.jar org.jmeterplugins.repository.PluginManagerCMDInstaller
          
          # 5. Instalar el conjunto de Custom Thread Groups (incluye Ultimate Thread Group)
          java -jar lib/cmdrunner-2.3.jar \
            --tool org.jmeterplugins.repository.PluginManagerCMD \
            install jpgc-casutg
          
          echo "Plugins installed successfully!"
          
          # Verificar instalaci√≥n de plugins
          echo "Verifying plugins installation..."
          ls -la /opt/jmeter/lib/ext/*.jar | grep -E "(casutg|cmn|json)"

      # 5Ô∏è‚É£ Instalar Taurus (BZT)
      - name: Install Taurus
        run: |
          sudo apt-get update
          sudo apt-get install -y python3-pip python3-venv python3-dev
          pip3 install --upgrade pip
          pip3 install bzt
      
      - name: Run Performance Tests with Taurus
        env:
          TEST_SCENARIO: ${{ github.event.inputs.test_scenario || 'load-test.yml' }}
          TEST_DURATION: ${{ github.event.inputs.duration || '5' }}
        run: |
          echo "Running performance tests with scenario: ${TEST_SCENARIO}"
          echo "Test duration: ${TEST_DURATION} minutes"
          
          # Crear directorio de plugins temporal
          mkdir -p ./temp_plugins
          cp /opt/jmeter/lib/ext/*.jar ./temp_plugins/
          
          # Ejecutar Taurus con configuraci√≥n espec√≠fica para plugins
          bzt ${TEST_SCENARIO} \
            -o modules.jmeter.path=/opt/jmeter \
            -o modules.jmeter.plugins-path=./temp_plugins \
            -o modules.jmeter.system-properties.jmeter.plugin.dir=./temp_plugins \
            -o modules.jmeter.detect-plugins=false \
            -o modules.jmeter.download-link= \
            -o modules.jmeter.version=5.6.3 \
            -o modules.jmeter.properties.DURACION=${TEST_DURATION} \
            -o modules.jmeter.properties.USUARIOS=10 \
            -o settings.artifacts-dir=./performance-results \
            -o modules.blazemeter.token="" \
            -o modules.blazemeter.upload-artifacts=false \
            -o modules.blazemeter.send-report=false \
            -o modules.blazemeter.browser-open=false \
            -report
          echo "Taurus execution completed!"

      # 7Ô∏è‚É£ Generar reporte HTML de JMeter (si hay archivos JTL)
      - name: Generate JMeter HTML Report
        if: always()
        run: |
          echo "Generating JMeter HTML reports..."
          
          # Buscar archivos JTL generados
          JTL_FILES=$(find ./performance-results -name "*.jtl" -type f | head -1)
          
          if [ -n "$JTL_FILES" ] && [ -f "$JTL_FILES" ]; then
            echo "Found JTL file: ${JTL_FILES}"
            
            # Crear directorio para reporte HTML
            mkdir -p ./jmeter-html-report
            
            # Generar reporte HTML usando JMeter
            /opt/jmeter/bin/jmeter \
              -g "${JTL_FILES}" \
              -o ./jmeter-html-report
              
            echo "HTML report generated successfully!"
          else
            echo "No JTL files found for HTML report generation."
          fi

      # 8Ô∏è‚É£ Subir resultados de Taurus
      - name: Upload Taurus Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: taurus-performance-results
          path: |
            ./performance-results/
            **/*.jtl
            **/*.csv
            **/*.log
            **/*.yml
            **/*.xml
          retention-days: 30

      # 9Ô∏è‚É£ Subir reporte HTML de JMeter
      - name: Upload JMeter HTML Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: jmeter-html-report
          path: ./jmeter-html-report/
          retention-days: 30

      # üîü Publicar m√©tricas clave (opcional)
      - name: Extract Key Metrics
        if: always()
        run: |
          echo "Extracting key performance metrics..."
          
          # Buscar archivo de resultados principal
          RESULT_FILE=$(find ./performance-results -name "*kpi.jtl" -o -name "*.csv" | head -1)
          
          if [ -n "$RESULT_FILE" ] && [ -f "$RESULT_FILE" ]; then
            echo "=== PERFORMANCE METRICS SUMMARY ==="
            echo "Results file: ${RESULT_FILE}"
            
            # Extraer m√©tricas b√°sicas (ejemplo)
            if command -v awk &> /dev/null; then
              echo "Sample data from results:"
              head -5 "${RESULT_FILE}"
            fi
            
            # Contar n√∫mero de requests
            if [ -f "${RESULT_FILE}" ]; then
              TOTAL_REQUESTS=$(tail -n +2 "${RESULT_FILE}" | wc -l)
              echo "Total requests: ${TOTAL_REQUESTS}"
            fi
          else
            echo "No results file found for metrics extraction."
          fi
          
          echo "=== WORKFLOW COMPLETED ==="
