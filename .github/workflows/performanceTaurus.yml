name: Performance Tests (Taurus with JMeter)

on:
  workflow_dispatch:
    inputs:
      test_scenario:
        description: 'Test scenario to run'
        required: false
        default: 'load-test.yml'
      duration:
        description: 'Test duration (minutes)'
        required: false
        default: '5'

jobs:
  performance:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      # 1Ô∏è‚É£ Checkout
      - name: Checkout code
        uses: actions/checkout@v4

      # 2Ô∏è‚É£ Java 17
      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: '17'

      # 3Ô∏è‚É£ Install JMeter
      - name: Install JMeter
        run: |
          JMETER_VERSION=5.6.3
          curl -L https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-${JMETER_VERSION}.tgz | tar -xz
          sudo mv apache-jmeter-${JMETER_VERSION} /opt/jmeter
          echo "/opt/jmeter/bin" >> $GITHUB_PATH
          jmeter --version

      # 4Ô∏è‚É£ Install JMeter Plugins (correct way)
      - name: Install JMeter Plugins
        run: |
          curl -L https://jmeter-plugins.org/get/ \
            -o /opt/jmeter/lib/ext/jmeter-plugins-manager.jar

          curl -L https://repo1.maven.org/maven2/kg/apc/cmdrunner/2.3/cmdrunner-2.3.jar \
            -o /opt/jmeter/lib/cmdrunner-2.3.jar

          jmeter --version

          cd /opt/jmeter
          java -cp lib/ext/jmeter-plugins-manager.jar \
            org.jmeterplugins.repository.PluginManagerCMDInstaller

          java -jar lib/cmdrunner-2.3.jar \
            --tool org.jmeterplugins.repository.PluginManagerCMD \
            install jpgc-casutg

          ls lib/ext | grep casutg

      # 5Ô∏è‚É£ Install Taurus
      - name: Install Taurus
        run: |
          sudo apt-get update
          sudo apt-get install -y python3-pip
          pip3 install --upgrade pip
          pip3 install bzt

      # 6Ô∏è‚É£ Run Taurus
      - name: Run Performance Tests with Taurus
        env:
          TEST_SCENARIO: ${{ github.event.inputs.test_scenario }}
          TEST_DURATION: ${{ github.event.inputs.duration }}
        run: |
          mkdir -p performance-results

          bzt ${TEST_SCENARIO} \
            -o modules.jmeter.path=/opt/jmeter \
            -o modules.jmeter.version=5.6.3 \
            -o modules.jmeter.properties.DURACION=${TEST_DURATION} \
            -o modules.jmeter.properties.USUARIOS=10 \
            -o settings.artifacts-dir=performance-results \
            -report

      # 7Ô∏è‚É£ Generate JMeter HTML Report
      - name: Generate JMeter HTML Report
        if: always()
        run: |
          JTL=$(find performance-results -name "*.jtl" | head -1)

          if [ -z "$JTL" ]; then
            echo "‚ùå No JTL file found"
            exit 0
          fi

          mkdir -p jmeter-html-report

          jmeter -g "$JTL" -o jmeter-html-report

          echo "‚úÖ HTML report generated"

      # 8Ô∏è‚É£ Upload Taurus Results
      - name: Upload Taurus Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: taurus-results
          path: performance-results/
          retention-days: 30

      # 9Ô∏è‚É£ Upload JMeter HTML Report
      - name: Upload JMeter HTML Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: jmeter-html-report
          path: jmeter-html-report/
          retention-days: 30

      # üîü Extract basic metrics
      - name: Extract Key Metrics
        if: always()
        run: |
          echo "=== METRICS SUMMARY ==="
          JTL=$(find performance-results -name "*.jtl" | head -1)

          if [ -n "$JTL" ]; then
            echo "File: $JTL"
            echo "Total samples:"
            tail -n +2 "$JTL" | wc -l
          else
            echo "No results file found"
          fi
